{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"10.10_prepare_data.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ddfo42JUxiv2"},"source":["\n","# TensorFlow Object Detection: Подготовка данных для обучения\n","\n","https://github.com/tensorflow/models/tree/master/research/object_detection"]},{"cell_type":"markdown","metadata":{"id":"BNXSkTUskE2G"},"source":["### Монтирование Google Drive\n","Для данного демо нам понадобятся несколько ноутбуков, которые должны работать с одними и теме же данными. Поэтому, чтобы все ноутбуки имели доступ к нужным данным, нам будет необходимо подключить диск Google Drive и сохранять все данные на нём (включая данные, скачанные из интернета).\n","\n","Для монтирования диска нужно выполнить данный блок, перейти по ссылке, получить код, скопировать его в поле ниже (в этом блоке) и нажать Enter\n","\n","После монтирования диск будет находиться здесь: `/content/drive/My Drive`"]},{"cell_type":"code","metadata":{"id":"k9eAdzWXyAHd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635622855934,"user_tz":-180,"elapsed":17718,"user":{"displayName":"София Хуциева","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01759155684546007455"}},"outputId":"ae37bd03-07d3-4ec7-ac4a-5388b45132fd"},"source":["!pip install tensorflow==1.15"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["      Successfully uninstalled tensorflow-2.6.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-probability 0.14.1 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n","kapre 0.3.5 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n","Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"]}]},{"cell_type":"code","metadata":{"id":"HAsG6Dc8kuQk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635622878485,"user_tz":-180,"elapsed":21804,"user":{"displayName":"София Хуциева","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01759155684546007455"}},"outputId":"a6e8d780-c859-4652-a8d7-3c52ca4f9115"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"xnnmVH__kx5B"},"source":["### Рабочая директория\n","Все данные будем хранить в директории `/content/drive/My Drive/tf_od_demo` (TensorFlow Object Detection Demo)\n","\n","При первом запуске создадим директорию (если её еще не существует), в противном случае надо заменить True на False.\n","\n","При последующих подключениях к диску (в том числе в других ноутбуках) директорию создавать не надо, в ней уже будут сохранены все данные, которые мы туда поместили."]},{"cell_type":"code","metadata":{"id":"khoZUcm6lrbu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635622880501,"user_tz":-180,"elapsed":206,"user":{"displayName":"София Хуциева","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01759155684546007455"}},"outputId":"64467b82-cc85-43c5-d5bf-0afcc4817032"},"source":["if True:\n","    !mkdir \"/content/drive/My Drive/tf_od_demo\"\n","%cd \"/content/drive/My Drive/tf_od_demo\""],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘/content/drive/My Drive/tf_od_demo’: File exists\n","/content/drive/My Drive/tf_od_demo\n"]}]},{"cell_type":"markdown","metadata":{"id":"kk53xwHtalrN"},"source":["### Подготовка библиотеки `object_detection`\n","Библиотека `object_detection` находится в репозитории `tensorflow/models` в разделе `research`\n","\n","Необходимо склонировать код библиотеки и сконфигурировать модели (сбилдить прото модели).\n","\n","Этот шаг нужно сделать один раз (не повторять, если папка `models` уже находится в текущей директории).\n","\n","Подробнее: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md"]},{"cell_type":"code","metadata":{"id":"LPueN9mCBpHy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635088396176,"user_tz":-180,"elapsed":10165,"user":{"displayName":"София Хуциева","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01759155684546007455"}},"outputId":"27d5b5ce-cb23-4ccb-cff0-ee0da714651a"},"source":["if True:\n","  \n","    !git clone https://github.com/tensorflow/models\n","    !cd models/research && protoc object_detection/protos/*.proto --python_out=.\n","    !cd models/research && export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim && python object_detection/builders/model_builder_test.py"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'models' already exists and is not an empty directory.\n","^C\n","Traceback (most recent call last):\n","  File \"object_detection/builders/model_builder_test.py\", line 21, in <module>\n","    from object_detection.builders import model_builder\n","  File \"/content/drive/My Drive/tf_od_demo/models/research/object_detection/builders/model_builder.py\", line 23, in <module>\n","    from object_detection.builders import anchor_generator_builder\n","  File \"/content/drive/My Drive/tf_od_demo/models/research/object_detection/builders/anchor_generator_builder.py\", line 23, in <module>\n","    from object_detection.anchor_generators import flexible_grid_anchor_generator\n","  File \"/content/drive/My Drive/tf_od_demo/models/research/object_detection/anchor_generators/flexible_grid_anchor_generator.py\", line 19, in <module>\n","    from object_detection.anchor_generators import grid_anchor_generator\n","  File \"/content/drive/My Drive/tf_od_demo/models/research/object_detection/anchor_generators/grid_anchor_generator.py\", line 27, in <module>\n","    from object_detection.utils import ops\n","  File \"/content/drive/My Drive/tf_od_demo/models/research/object_detection/utils/ops.py\", line 28, in <module>\n","    import tf_slim as slim\n","ModuleNotFoundError: No module named 'tf_slim'\n"]}]},{"cell_type":"markdown","metadata":{"id":"RFCMljCEx9VW"},"source":["### Загрузка библиотек\n","Загрузка TensorFlow и других библиотек. Кроме того, загрузка модуля `dataset_util` из пакета `object_detection`, который будет нужен для создания датасета в нужном формате."]},{"cell_type":"code","metadata":{"id":"jH8kQ2q30B03","executionInfo":{"status":"ok","timestamp":1635622900876,"user_tz":-180,"elapsed":3825,"user":{"displayName":"София Хуциева","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01759155684546007455"}}},"source":["import pandas as pd\n","import os\n","from PIL import Image\n","\n","import tensorflow as tf\n","\n","import sys\n","sys.path.insert(0, 'models/research')\n","\n","from object_detection.utils import dataset_util"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JzfjZKWhebb9"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"hZmalcqDcwWG"},"source":["### Функция для создания одного обучающего образца\n","В этой функции создаётся экземпляр класса `tf.train.Example`, который соответствует одной обучающей картике. Ей могут соответствовать несколько ground-truth баундинг боксов. Однако, конкретно в данном примере на картинке есть строго один бокс. В противном случае списки `xmins`, `xmaxs`, `ymins`, `ymaxs`, `classes_text`, `classes` должны иметь соответствующее количество элементов ( = кол-ву боксов на данной картинке).\n","\n","Создавать экземпляры класса `tf.train.Example` можно произвольным способом. В данном примере на вход в функцию подаётся строка из CSV файла (`annot.csv`). Главное -- заполнить соовтестсвующие поля словаре `feature={...}`\n","\n","Подробнее: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md"]},{"cell_type":"code","metadata":{"id":"Dvz1hSw70OyQ","executionInfo":{"status":"ok","timestamp":1635622909199,"user_tz":-180,"elapsed":206,"user":{"displayName":"София Хуциева","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01759155684546007455"}}},"source":["import numpy as np\n","def create_tf_example(example):\n","  \n","    img_fpath = os.path.join('my_data', example.id)\n","    img = Image.open(img_fpath)\n","    height = img.size[1]\n","    width = img.size[0]\n","    filename = str.encode(example.id)\n","    with open(img_fpath, mode='rb') as f:\n","        encoded_image_data = f.read()\n","    image_format = b'jpeg'\n","\n","    # List of normalized left x coordinates in bounding box (1 per box)\n","    xmins = [example.xmin / float(width)] \n","    # List of normalized right x coordinates in bounding box # (1 per box)\n","    xmaxs = [example.xmax / float(width)] \n","    # List of normalized top y coordinates in bounding box (1 per box)\n","    ymins = [example.ymin / float(height)] \n","    # List of normalized bottom y coordinates in bounding box # (1 per box)\n","    ymaxs = [example.ymax / float(height)] \n","    # List of string class name of bounding box (1 per box)\n","    #classes_text = example.class_\n","    # List of integer class id of bounding box (1 per box)\n","    classes = [np.int(example.label)]\n","    if classes == [1]:\n","      classes_text = [b'Cube1']\n","    else: \n","      classes_text = [b'Cube2']\n","    print(classes_text)\n","  \n","    tf_example = tf.train.Example(features=tf.train.Features(feature={\n","      'image/height': dataset_util.int64_feature(height),\n","      'image/width': dataset_util.int64_feature(width),\n","      'image/filename': dataset_util.bytes_feature(filename),\n","      'image/source_id': dataset_util.bytes_feature(filename),\n","      'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n","      'image/format': dataset_util.bytes_feature(image_format),\n","      'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n","      'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n","      'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n","      'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n","      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n","      'image/object/class/label': dataset_util.int64_list_feature(classes),\n","  }))\n","    \n","\n","    # if classes == [1]:\n","\n","    #   tf_example = tf.train.Example(features=tf.train.Features(feature={\n","    #       'image/height': dataset_util.int64_feature(height),\n","    #       'image/width': dataset_util.int64_feature(width),\n","    #       'image/filename': dataset_util.bytes_feature(filename),\n","    #       'image/source_id': dataset_util.bytes_feature(filename),\n","    #       'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n","    #       'image/format': dataset_util.bytes_feature(image_format),\n","    #       'image/object/bbox1/xmin': dataset_util.float_list_feature(xmins),\n","    #       'image/object/bbox1/xmax': dataset_util.float_list_feature(xmaxs),\n","    #       'image/object/bbox1/ymin': dataset_util.float_list_feature(ymins),\n","    #       'image/object/bbox1/ymax': dataset_util.float_list_feature(ymaxs),\n","    #       'image/object/class1/text': dataset_util.bytes_list_feature(classes_text),\n","    #       'image/object/class1/label': dataset_util.int64_list_feature(classes),\n","    #   }))\n","    \n","    # else:\n","      \n","    #   tf_example = tf.train.Example(features=tf.train.Features(feature={\n","    #       'image/height': dataset_util.int64_feature(height),\n","    #       'image/width': dataset_util.int64_feature(width),\n","    #       'image/filename': dataset_util.bytes_feature(filename),\n","    #       'image/source_id': dataset_util.bytes_feature(filename),\n","    #       'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n","    #       'image/format': dataset_util.bytes_feature(image_format),\n","    #       'image/object/bbox2/xmin': dataset_util.float_list_feature(xmins),\n","    #       'image/object/bbox2/xmax': dataset_util.float_list_feature(xmaxs),\n","    #       'image/object/bbox2/ymin': dataset_util.float_list_feature(ymins),\n","    #       'image/object/bbox2/ymax': dataset_util.float_list_feature(ymaxs),\n","    #       'image/object/class2/text': dataset_util.bytes_list_feature(classes_text),\n","    #       'image/object/class2/label': dataset_util.int64_list_feature(classes),\n","    #   }))\n","\n","\n","\n","    return tf_example"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ow1NNywGecQ2"},"source":["### Чтение CSV файла с разметкой\n","В данном файле представлена разметка обучающих изображений. Сам файл и его формат показаны лишь для примера, они никак не связаны с библиотекой `object_detection`. Наша финальная цель -- создать датасет в формате `TFRecord`, состоящий из экземпляров `tf.train.Example`.\n","\n","---\n","\n","В данном примере формат файла annot.csv следующий (один бокс на файл):\n","\n","id,xmin,ymin,xmax,ymax\n","\n","1.jpg,261,260,601,615\n","\n","2.jpg,130,429,401,734\n","\n","...\n","\n","---\n","\n","Перед запуском этого блока загрузите необходимые данные (папка `my_data`) в текущую рабочую директорию (tf_od_demo). Один из вариантов, как это можно сделать, это загрузить архив `my_data.7z`, а затем разархивировать его с помощью команды:\n","\n","`!7z x my_data.7z`"]},{"cell_type":"code","metadata":{"id":"k8alLq1uilZz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635070653025,"user_tz":-180,"elapsed":368,"user":{"displayName":"София Хуциева","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01759155684546007455"}},"outputId":"5c6b0397-cc58-4dbd-d0d4-9b720f832d79"},"source":["if True:\n","    !7z x my_data.7z"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n","p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n","\n","Scanning the drive for archives:\n","  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b\n","ERROR: No more files\n","my_data.7z\n","\n","\n","\n","System ERROR:\n","Unknown error -2147024872\n"]}]},{"cell_type":"code","metadata":{"id":"YpwJXq1SYy7S","colab":{"base_uri":"https://localhost:8080/","height":358},"executionInfo":{"status":"ok","timestamp":1635622914902,"user_tz":-180,"elapsed":567,"user":{"displayName":"София Хуциева","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01759155684546007455"}},"outputId":"182453a0-2439-4937-8b9d-c551af84d8be"},"source":["annot = pd.read_csv('my_data/annot.csv')\n","annot.head(10)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>xmin</th>\n","      <th>ymin</th>\n","      <th>xmax</th>\n","      <th>ymax</th>\n","      <th>class_</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.jpg</td>\n","      <td>154</td>\n","      <td>14</td>\n","      <td>563</td>\n","      <td>543</td>\n","      <td>[b\"Cube1\"]</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.jpg</td>\n","      <td>634</td>\n","      <td>123</td>\n","      <td>1060</td>\n","      <td>543</td>\n","      <td>[b\"Cube2\"]</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.jpg</td>\n","      <td>95</td>\n","      <td>17</td>\n","      <td>341</td>\n","      <td>364</td>\n","      <td>[b\"Cube1\"]</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.jpg</td>\n","      <td>382</td>\n","      <td>78</td>\n","      <td>642</td>\n","      <td>332</td>\n","      <td>[b\"Cube2\"]</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3.jpg</td>\n","      <td>146</td>\n","      <td>59</td>\n","      <td>399</td>\n","      <td>389</td>\n","      <td>[b\"Cube1\"]</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>3.jpg</td>\n","      <td>422</td>\n","      <td>94</td>\n","      <td>659</td>\n","      <td>337</td>\n","      <td>[b\"Cube2\"]</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>4.jpg</td>\n","      <td>183</td>\n","      <td>17</td>\n","      <td>594</td>\n","      <td>529</td>\n","      <td>[b\"Cube1\"]</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>4.jpg</td>\n","      <td>663</td>\n","      <td>134</td>\n","      <td>1056</td>\n","      <td>537</td>\n","      <td>[b\"Cube2\"]</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>5.jpg</td>\n","      <td>269</td>\n","      <td>106</td>\n","      <td>663</td>\n","      <td>666</td>\n","      <td>[b\"Cube1\"]</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>5.jpg</td>\n","      <td>705</td>\n","      <td>187</td>\n","      <td>1090</td>\n","      <td>549</td>\n","      <td>[b\"Cube2\"]</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      id  xmin  ymin  xmax  ymax      class_  label\n","0  1.jpg   154    14   563   543  [b\"Cube1\"]      1\n","1  1.jpg   634   123  1060   543  [b\"Cube2\"]      2\n","2  2.jpg    95    17   341   364  [b\"Cube1\"]      1\n","3  2.jpg   382    78   642   332  [b\"Cube2\"]      2\n","4  3.jpg   146    59   399   389  [b\"Cube1\"]      1\n","5  3.jpg   422    94   659   337  [b\"Cube2\"]      2\n","6  4.jpg   183    17   594   529  [b\"Cube1\"]      1\n","7  4.jpg   663   134  1056   537  [b\"Cube2\"]      2\n","8  5.jpg   269   106   663   666  [b\"Cube1\"]      1\n","9  5.jpg   705   187  1090   549  [b\"Cube2\"]      2"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VCNm5E_gjluo","executionInfo":{"status":"ok","timestamp":1635622918652,"user_tz":-180,"elapsed":196,"user":{"displayName":"София Хуциева","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01759155684546007455"}},"outputId":"43f3f40f-52e3-4a08-db24-e22efcbe23b1"},"source":["for idx, row in annot.iterrows():\n","  print(row.label)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","2\n","1\n","2\n","1\n","2\n","1\n","2\n","1\n","2\n","1\n","2\n","1\n","2\n","1\n","2\n","1\n","2\n"]}]},{"cell_type":"code","metadata":{"id":"0YsRggrDuhCf"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"90HTWYRmhRrP"},"source":["### Создание TFRecord\n","Здесь мы создаём финальный датасет в формате `TFRecord`, который необходим для запуска обучения TF Object Detection. \n","\n","В цикле по всем обучающим образцам создаем `TF Example` и записываем его в `TF Record`."]},{"cell_type":"code","metadata":{"id":"ReFXnPuwZLoB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635623453485,"user_tz":-180,"elapsed":216,"user":{"displayName":"София Хуциева","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01759155684546007455"}},"outputId":"88c0fe2c-361c-4367-e7d3-7abe29e99e25"},"source":["writer = tf.python_io.TFRecordWriter('my_data/train_data.record')\n","\n","for idx, row in annot.iterrows():\n","    tf_example = create_tf_example(row)\n","    writer.write(tf_example.SerializeToString())\n","\n","writer.close()"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[b'Cube1']\n","[b'Cube2']\n","[b'Cube1']\n","[b'Cube2']\n","[b'Cube1']\n","[b'Cube2']\n","[b'Cube1']\n","[b'Cube2']\n","[b'Cube1']\n","[b'Cube2']\n","[b'Cube1']\n","[b'Cube2']\n","[b'Cube1']\n","[b'Cube2']\n","[b'Cube1']\n","[b'Cube2']\n","[b'Cube1']\n","[b'Cube2']\n"]}]},{"cell_type":"code","metadata":{"id":"4Bl1CWfDr7QF"},"source":[""],"execution_count":null,"outputs":[]}]}