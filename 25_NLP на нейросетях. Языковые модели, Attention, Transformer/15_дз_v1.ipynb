{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "15_дз_v1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74c6700b-ea14-4e5b-95d5-c738a3d04d33"
      },
      "source": [
        "# Библиотеки"
      ],
      "id": "74c6700b-ea14-4e5b-95d5-c738a3d04d33"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c9e700c-b851-40ee-9a5c-25445bac8630"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "id": "9c9e700c-b851-40ee-9a5c-25445bac8630",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5f0a6cf-70c0-4b91-87ae-e35d1b7d9a33"
      },
      "source": [
        ""
      ],
      "id": "a5f0a6cf-70c0-4b91-87ae-e35d1b7d9a33",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16e9cec3-c1c1-4d15-8d3f-75444f79d942"
      },
      "source": [
        "# 1. Подготовка датасета"
      ],
      "id": "16e9cec3-c1c1-4d15-8d3f-75444f79d942"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9b91cd7-a526-4cc0-98db-03c7250b823e"
      },
      "source": [
        "with open('movie_conversations.txt', 'r') as file:\n",
        "    lines1 = file.read().splitlines()"
      ],
      "id": "b9b91cd7-a526-4cc0-98db-03c7250b823e",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5873c1ff-f389-475d-a2cd-fcac44c5558d"
      },
      "source": [
        "num = []\n",
        "for line1 in lines1:\n",
        "    num.append(line1[line1.index('[') + 1 : line1.index(']')].replace(\"'\", \"\"))"
      ],
      "id": "5873c1ff-f389-475d-a2cd-fcac44c5558d",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "353ba847-6f61-4aa4-a627-9744d9e17cf9"
      },
      "source": [
        "input_, output_ = [], []\n",
        "for num_ in num:\n",
        "    for i in range(len(num_.split(', ')) - 1):\n",
        "        input_.append(num_.split(', ')[i])\n",
        "        output_.append(num_.split(', ')[i + 1])"
      ],
      "id": "353ba847-6f61-4aa4-a627-9744d9e17cf9",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe5942c9-836f-439b-badd-8f8952fcd067"
      },
      "source": [
        ""
      ],
      "id": "fe5942c9-836f-439b-badd-8f8952fcd067",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26ed8b74-ee54-4a6c-954c-0ff434071c9c"
      },
      "source": [
        "with open('movie_lines.txt', 'r', encoding='ISO-8859-1') as file:\n",
        "    lines2 = file.read().splitlines()"
      ],
      "id": "26ed8b74-ee54-4a6c-954c-0ff434071c9c",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "KmOdNXcGb-Mi",
        "outputId": "e1687b7b-1027-4e60-da74-49bbdbc865ce"
      },
      "source": [
        "lines2[-1]"
      ],
      "id": "KmOdNXcGb-Mi",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"L666256 +++$+++ u9034 +++$+++ m616 +++$+++ VEREKER +++$+++ Colonel Durnford... William Vereker. I hear you 've been seeking Officers?\""
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xtRCer5ibvwu",
        "outputId": "9c7cfffc-e2aa-43ac-dffc-e2b0e15d0290"
      },
      "source": [
        "lines2[0][:lines2[0].index('+') - 1]"
      ],
      "id": "xtRCer5ibvwu",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'L1045'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2badf970-8295-46d4-8d0f-a60e610252ea",
        "outputId": "5ce7800f-c1ed-4368-a24d-cf40e0235580"
      },
      "source": [
        "name, line = [], []\n",
        "for line2 in lines2:\n",
        "  try:\n",
        "    name.append(line2[:line2.index('+') - 1])\n",
        "    for _ in range(4):\n",
        "        line2 = line2[line2.index('$')+1:]  \n",
        "    line.append(line2[4:]) \n",
        "  except:\n",
        "    print(name)"
      ],
      "id": "2badf970-8295-46d4-8d0f-a60e610252ea",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01c16fce-eac2-43b4-ba84-3b0b642d9ef5"
      },
      "source": [
        "line_name = {}\n",
        "for name, line in zip(name, line):\n",
        "    line_name[name] = line"
      ],
      "id": "01c16fce-eac2-43b4-ba84-3b0b642d9ef5",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b62c206-c364-43cf-a2d4-90a864486f47"
      },
      "source": [
        "line_name"
      ],
      "id": "4b62c206-c364-43cf-a2d4-90a864486f47",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a807e4c-0549-4ab9-b250-980b074899c8"
      },
      "source": [
        "input_texts, target_texts = [], []\n",
        "for input_1, output_1 in zip(input_, output_):\n",
        "    input_texts.append(line_name[input_1])\n",
        "    target_texts.append(line_name[output_1])"
      ],
      "id": "0a807e4c-0549-4ab9-b250-980b074899c8",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d7fa47a-c789-43f2-b20b-936694294450"
      },
      "source": [
        ""
      ],
      "id": "3d7fa47a-c789-43f2-b20b-936694294450",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1228f63-8e6c-43ae-9745-456a54cd41ac"
      },
      "source": [
        "# 2. Признаки"
      ],
      "id": "d1228f63-8e6c-43ae-9745-456a54cd41ac"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4abbea04-fcd0-47e2-94e8-200bfc547940"
      },
      "source": [
        "## 2.1 Подготовка словарей"
      ],
      "id": "4abbea04-fcd0-47e2-94e8-200bfc547940"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a4940e7-29b6-4f49-874d-345bcf7c0c52"
      },
      "source": [
        "def prepare_vocab(texts):\n",
        "    vocab = sorted(set(''.join(texts)))\n",
        "    vocab.append('<START>')\n",
        "    vocab.append('<END>')\n",
        "    vocab_size = len(vocab)\n",
        "    char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "    idx2char = np.array(vocab)\n",
        "    return vocab_size, char2idx, idx2char\n",
        "\n",
        "INPUT_VOCAB_SIZE, input_char2idx, input_idx2char = prepare_vocab(input_texts)\n",
        "TARGET_VOCAB_SIZE, target_char2idx, target_idx2char = prepare_vocab(target_texts)"
      ],
      "id": "9a4940e7-29b6-4f49-874d-345bcf7c0c52",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "64c10219-5864-4b26-b627-5324eb76b1e1"
      },
      "source": [
        "input_char2idx"
      ],
      "id": "64c10219-5864-4b26-b627-5324eb76b1e1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85bacbcd-d99a-4325-952c-54a5db365ebb"
      },
      "source": [
        ""
      ],
      "id": "85bacbcd-d99a-4325-952c-54a5db365ebb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55de2b2e-8fc0-429c-9d59-67966c289f83"
      },
      "source": [
        "## 2.2 Токенизация"
      ],
      "id": "55de2b2e-8fc0-429c-9d59-67966c289f83"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c151e62-cf13-4403-a72e-ba8e7b608d9d"
      },
      "source": [
        "input_texts_as_int = [[input_char2idx[c] for c in text] for text in input_texts]\n",
        "target_texts_as_int = [[target_char2idx[c] for c in text] for text in target_texts]\n",
        "\n",
        "encoder_input_seqs = [np.array(text) for text in input_texts_as_int]\n",
        "decoder_input_seqs = []\n",
        "decoder_target_seqs = []\n",
        "for target_text in target_texts_as_int:\n",
        "    decoder_input_seqs.append(np.array([target_char2idx['<START>']] + target_text))\n",
        "    decoder_target_seqs.append(np.array(target_text + [target_char2idx['<END>']]))"
      ],
      "id": "4c151e62-cf13-4403-a72e-ba8e7b608d9d",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b28c66f3-d42f-494e-b362-ec1baeb25a97"
      },
      "source": [
        ""
      ],
      "id": "b28c66f3-d42f-494e-b362-ec1baeb25a97",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "420897ac-b8f8-43aa-af8e-93464b6236af"
      },
      "source": [
        "## 2.3 Паддинг"
      ],
      "id": "420897ac-b8f8-43aa-af8e-93464b6236af"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7746ebb4-da0d-4327-8553-db459194fc44",
        "outputId": "a10e08b1-223f-4c26-fb4a-020e3e2f0ecb"
      },
      "source": [
        "max([len(seq) for seq in encoder_input_seqs]), np.mean([len(seq) for seq in encoder_input_seqs]), np.median([len(seq) for seq in encoder_input_seqs])"
      ],
      "id": "7746ebb4-da0d-4327-8553-db459194fc44",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1903, 53.6749828532236, 34.0)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afeca051-6589-44e3-bc39-5db02a4e70d2",
        "outputId": "0f3201d8-a01e-4c13-f031-27f5d4e8deac"
      },
      "source": [
        "max([len(seq) for seq in decoder_input_seqs]), np.mean([len(seq) for seq in decoder_input_seqs]), np.median([len(seq) for seq in decoder_input_seqs])"
      ],
      "id": "afeca051-6589-44e3-bc39-5db02a4e70d2",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3047, 56.47703234423507, 36.0)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed93e690-5a42-42e8-90ac-9b36c945f516"
      },
      "source": [
        "max_enc_seq_length = 64\n",
        "max_dec_seq_length = 64\n",
        "\n",
        "encoder_input_seqs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    encoder_input_seqs,\n",
        "    value=input_char2idx[' '],\n",
        "    padding='post',\n",
        "    maxlen=max_enc_seq_length)\n",
        "\n",
        "decoder_input_seqs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    decoder_input_seqs,\n",
        "    value=target_char2idx[' '],\n",
        "    padding='post',\n",
        "    maxlen=max_dec_seq_length)\n",
        "\n",
        "decoder_target_seqs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    decoder_target_seqs,\n",
        "    value=target_char2idx[' '],\n",
        "    padding='post',\n",
        "    maxlen=max_dec_seq_length)"
      ],
      "id": "ed93e690-5a42-42e8-90ac-9b36c945f516",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b8e099a-d202-4230-a7ff-16ed833bfb29"
      },
      "source": [
        ""
      ],
      "id": "6b8e099a-d202-4230-a7ff-16ed833bfb29",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44476264-50ce-4aef-ba57-f396e5b7602c"
      },
      "source": [
        "# 3. Модель"
      ],
      "id": "44476264-50ce-4aef-ba57-f396e5b7602c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmkIEOvzjaj7"
      },
      "source": [
        "## 3.1 Обучение"
      ],
      "id": "cmkIEOvzjaj7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0537771-03e7-4940-8c5f-f78752be8f78"
      },
      "source": [
        "H_SIZE = 256 # Размерность скрытого состояния LSTM\n",
        "EMB_SIZE = 256 # размерность эмбеддингов (и для входных и для выходных цепочек)\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed = tf.keras.layers.Embedding(INPUT_VOCAB_SIZE, EMB_SIZE)\n",
        "        self.lstm = tf.keras.layers.LSTM(H_SIZE, return_sequences=False, return_state=True)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embed(x)\n",
        "        _, h, c = self.lstm(out)\n",
        "        state = (h, c)\n",
        "        return state\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed = tf.keras.layers.Embedding(TARGET_VOCAB_SIZE, EMB_SIZE)\n",
        "        self.lstm = tf.keras.layers.LSTM(H_SIZE, return_sequences=True, return_state=True)\n",
        "        self.fc = tf.keras.layers.Dense(TARGET_VOCAB_SIZE, activation='softmax')\n",
        "        \n",
        "    def call(self, x, init_state):\n",
        "        out = self.embed(x)\n",
        "        out, h, c = self.lstm(out, initial_state=init_state)\n",
        "        out = self.fc(out)\n",
        "        state = (h, c)\n",
        "        return out, state\n",
        "\n",
        "encoder_model = Encoder()\n",
        "decoder_model = Decoder()\n",
        "\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "decoder_inputs = tf.keras.layers.Input(shape=(None,))"
      ],
      "id": "a0537771-03e7-4940-8c5f-f78752be8f78",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76b86f7d-8ac4-4960-bbe5-04b83f1a5f7b",
        "outputId": "94216f30-f98f-43d6-ee56-c3ba7c127123"
      },
      "source": [
        "type(encoder_inputs)"
      ],
      "id": "76b86f7d-8ac4-4960-bbe5-04b83f1a5f7b",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras.engine.keras_tensor.KerasTensor"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38578435-5b43-430c-9705-4926c5081b92"
      },
      "source": [
        "enc_state = encoder_model(encoder_inputs)\n",
        "decoder_outputs, _ = decoder_model(decoder_inputs, enc_state)\n",
        "\n",
        "seq2seq = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "id": "38578435-5b43-430c-9705-4926c5081b92",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efd5b86a-97e4-4696-b38b-0f4b74fa95b3",
        "outputId": "dc874f1b-ef58-4d54-f280-bf0e73b68eb0"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100\n",
        "\n",
        "loss = tf.losses.SparseCategoricalCrossentropy()\n",
        "seq2seq.compile(optimizer='rmsprop', loss=loss, metrics=['accuracy'])\n",
        "seq2seq.fit([encoder_input_seqs, decoder_input_seqs], decoder_target_seqs,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS)"
      ],
      "id": "efd5b86a-97e4-4696-b38b-0f4b74fa95b3",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3463/3463 [==============================] - 194s 54ms/step - loss: 1.0183 - accuracy: 0.7040\n",
            "Epoch 2/100\n",
            "3463/3463 [==============================] - 185s 53ms/step - loss: 0.8313 - accuracy: 0.7500\n",
            "Epoch 3/100\n",
            "3463/3463 [==============================] - 184s 53ms/step - loss: 0.7992 - accuracy: 0.7585\n",
            "Epoch 4/100\n",
            "3463/3463 [==============================] - 185s 53ms/step - loss: 0.7828 - accuracy: 0.7630\n",
            "Epoch 5/100\n",
            "3463/3463 [==============================] - 184s 53ms/step - loss: 0.7722 - accuracy: 0.7658\n",
            "Epoch 6/100\n",
            "3463/3463 [==============================] - 184s 53ms/step - loss: 0.7646 - accuracy: 0.7678\n",
            "Epoch 7/100\n",
            "3463/3463 [==============================] - 184s 53ms/step - loss: 0.7589 - accuracy: 0.7693\n",
            "Epoch 8/100\n",
            "3463/3463 [==============================] - 185s 54ms/step - loss: 0.7543 - accuracy: 0.7705\n",
            "Epoch 9/100\n",
            "3463/3463 [==============================] - 185s 53ms/step - loss: 0.7506 - accuracy: 0.7715\n",
            "Epoch 10/100\n",
            "3463/3463 [==============================] - 185s 53ms/step - loss: 0.7475 - accuracy: 0.7724\n",
            "Epoch 11/100\n",
            "3463/3463 [==============================] - 185s 53ms/step - loss: 0.7449 - accuracy: 0.7730\n",
            "Epoch 12/100\n",
            "3463/3463 [==============================] - 184s 53ms/step - loss: 0.7426 - accuracy: 0.7737\n",
            "Epoch 13/100\n",
            "3463/3463 [==============================] - 185s 53ms/step - loss: 0.7407 - accuracy: 0.7742\n",
            "Epoch 14/100\n",
            "3463/3463 [==============================] - 185s 53ms/step - loss: 0.7389 - accuracy: 0.7747\n",
            "Epoch 15/100\n",
            "3463/3463 [==============================] - 184s 53ms/step - loss: 0.7374 - accuracy: 0.7751\n",
            "Epoch 16/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7359 - accuracy: 0.7755\n",
            "Epoch 17/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7346 - accuracy: 0.7759\n",
            "Epoch 18/100\n",
            "3463/3463 [==============================] - 181s 52ms/step - loss: 0.7334 - accuracy: 0.7762\n",
            "Epoch 19/100\n",
            "3463/3463 [==============================] - 181s 52ms/step - loss: 0.7323 - accuracy: 0.7766\n",
            "Epoch 20/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7313 - accuracy: 0.7769\n",
            "Epoch 21/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7304 - accuracy: 0.7771\n",
            "Epoch 22/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7296 - accuracy: 0.7774\n",
            "Epoch 23/100\n",
            "3463/3463 [==============================] - 181s 52ms/step - loss: 0.7287 - accuracy: 0.7776\n",
            "Epoch 24/100\n",
            "3463/3463 [==============================] - 182s 52ms/step - loss: 0.7279 - accuracy: 0.7778\n",
            "Epoch 25/100\n",
            "3463/3463 [==============================] - 181s 52ms/step - loss: 0.7276 - accuracy: 0.7779\n",
            "Epoch 26/100\n",
            "3463/3463 [==============================] - 181s 52ms/step - loss: 0.7266 - accuracy: 0.7782\n",
            "Epoch 27/100\n",
            "3463/3463 [==============================] - 181s 52ms/step - loss: 0.7259 - accuracy: 0.7784\n",
            "Epoch 28/100\n",
            "3463/3463 [==============================] - 181s 52ms/step - loss: 0.7253 - accuracy: 0.7786\n",
            "Epoch 29/100\n",
            "3463/3463 [==============================] - 181s 52ms/step - loss: 0.7247 - accuracy: 0.7787\n",
            "Epoch 30/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7242 - accuracy: 0.7789\n",
            "Epoch 31/100\n",
            "3463/3463 [==============================] - 184s 53ms/step - loss: 0.7236 - accuracy: 0.7790\n",
            "Epoch 32/100\n",
            "3463/3463 [==============================] - 184s 53ms/step - loss: 0.7232 - accuracy: 0.7791\n",
            "Epoch 33/100\n",
            "3463/3463 [==============================] - 185s 53ms/step - loss: 0.7226 - accuracy: 0.7793\n",
            "Epoch 34/100\n",
            "3463/3463 [==============================] - 184s 53ms/step - loss: 0.7222 - accuracy: 0.7794\n",
            "Epoch 35/100\n",
            "3463/3463 [==============================] - 185s 54ms/step - loss: 0.7217 - accuracy: 0.7795\n",
            "Epoch 36/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7213 - accuracy: 0.7797\n",
            "Epoch 37/100\n",
            "3463/3463 [==============================] - 184s 53ms/step - loss: 0.7210 - accuracy: 0.7798\n",
            "Epoch 38/100\n",
            "3463/3463 [==============================] - 185s 53ms/step - loss: 0.7206 - accuracy: 0.7799\n",
            "Epoch 39/100\n",
            "3463/3463 [==============================] - 186s 54ms/step - loss: 0.7201 - accuracy: 0.7800\n",
            "Epoch 40/100\n",
            "3463/3463 [==============================] - 186s 54ms/step - loss: 0.7198 - accuracy: 0.7801\n",
            "Epoch 41/100\n",
            "3463/3463 [==============================] - 185s 53ms/step - loss: 0.7195 - accuracy: 0.7802\n",
            "Epoch 42/100\n",
            "3463/3463 [==============================] - 185s 53ms/step - loss: 0.7191 - accuracy: 0.7804\n",
            "Epoch 43/100\n",
            "3463/3463 [==============================] - 185s 53ms/step - loss: 0.7188 - accuracy: 0.7804\n",
            "Epoch 44/100\n",
            "3463/3463 [==============================] - 185s 54ms/step - loss: 0.7184 - accuracy: 0.7806\n",
            "Epoch 45/100\n",
            "3463/3463 [==============================] - 185s 53ms/step - loss: 0.7182 - accuracy: 0.7806\n",
            "Epoch 46/100\n",
            "3463/3463 [==============================] - 185s 54ms/step - loss: 0.7179 - accuracy: 0.7807\n",
            "Epoch 47/100\n",
            "3463/3463 [==============================] - 185s 54ms/step - loss: 0.7177 - accuracy: 0.7809\n",
            "Epoch 48/100\n",
            "3463/3463 [==============================] - 184s 53ms/step - loss: 0.7175 - accuracy: 0.7808\n",
            "Epoch 49/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7172 - accuracy: 0.7809\n",
            "Epoch 50/100\n",
            "3463/3463 [==============================] - 182s 52ms/step - loss: 0.7169 - accuracy: 0.7810\n",
            "Epoch 51/100\n",
            "3463/3463 [==============================] - 182s 53ms/step - loss: 0.7167 - accuracy: 0.7811\n",
            "Epoch 52/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7164 - accuracy: 0.7812\n",
            "Epoch 53/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7162 - accuracy: 0.7812\n",
            "Epoch 54/100\n",
            "3463/3463 [==============================] - 181s 52ms/step - loss: 0.7160 - accuracy: 0.7813\n",
            "Epoch 55/100\n",
            "3463/3463 [==============================] - 182s 53ms/step - loss: 0.7159 - accuracy: 0.7813\n",
            "Epoch 56/100\n",
            "3463/3463 [==============================] - 181s 52ms/step - loss: 0.7157 - accuracy: 0.7814\n",
            "Epoch 57/100\n",
            "3463/3463 [==============================] - 182s 52ms/step - loss: 0.7155 - accuracy: 0.7814\n",
            "Epoch 58/100\n",
            "3463/3463 [==============================] - 181s 52ms/step - loss: 0.7154 - accuracy: 0.7815\n",
            "Epoch 59/100\n",
            "3463/3463 [==============================] - 181s 52ms/step - loss: 0.7152 - accuracy: 0.7815\n",
            "Epoch 60/100\n",
            "3463/3463 [==============================] - 182s 53ms/step - loss: 0.7151 - accuracy: 0.7816\n",
            "Epoch 61/100\n",
            "3463/3463 [==============================] - 182s 53ms/step - loss: 0.7149 - accuracy: 0.7816\n",
            "Epoch 62/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7149 - accuracy: 0.7817\n",
            "Epoch 63/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7147 - accuracy: 0.7817\n",
            "Epoch 64/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7146 - accuracy: 0.7818\n",
            "Epoch 65/100\n",
            "3463/3463 [==============================] - 182s 53ms/step - loss: 0.7145 - accuracy: 0.7817\n",
            "Epoch 66/100\n",
            "3463/3463 [==============================] - 182s 52ms/step - loss: 0.7145 - accuracy: 0.7817\n",
            "Epoch 67/100\n",
            "3463/3463 [==============================] - 182s 52ms/step - loss: 0.7144 - accuracy: 0.7819\n",
            "Epoch 68/100\n",
            "3463/3463 [==============================] - 182s 53ms/step - loss: 0.7143 - accuracy: 0.7819\n",
            "Epoch 69/100\n",
            "3463/3463 [==============================] - 184s 53ms/step - loss: 0.7143 - accuracy: 0.7819\n",
            "Epoch 70/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7143 - accuracy: 0.7819\n",
            "Epoch 71/100\n",
            "3463/3463 [==============================] - 184s 53ms/step - loss: 0.7141 - accuracy: 0.7819\n",
            "Epoch 72/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7140 - accuracy: 0.7820\n",
            "Epoch 73/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7140 - accuracy: 0.7819\n",
            "Epoch 74/100\n",
            "3463/3463 [==============================] - 182s 53ms/step - loss: 0.7139 - accuracy: 0.7819\n",
            "Epoch 75/100\n",
            "3463/3463 [==============================] - 182s 53ms/step - loss: 0.7138 - accuracy: 0.7820\n",
            "Epoch 76/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7138 - accuracy: 0.7820\n",
            "Epoch 77/100\n",
            "3463/3463 [==============================] - 182s 53ms/step - loss: 0.7138 - accuracy: 0.7820\n",
            "Epoch 78/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7138 - accuracy: 0.7820\n",
            "Epoch 79/100\n",
            "3463/3463 [==============================] - 182s 52ms/step - loss: 0.7137 - accuracy: 0.7821\n",
            "Epoch 80/100\n",
            "3463/3463 [==============================] - 182s 53ms/step - loss: 0.7135 - accuracy: 0.7821\n",
            "Epoch 81/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7137 - accuracy: 0.7821\n",
            "Epoch 82/100\n",
            "3463/3463 [==============================] - 182s 53ms/step - loss: 0.7140 - accuracy: 0.7820\n",
            "Epoch 83/100\n",
            "3463/3463 [==============================] - 182s 53ms/step - loss: 0.7138 - accuracy: 0.7820\n",
            "Epoch 84/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7136 - accuracy: 0.7820\n",
            "Epoch 85/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7136 - accuracy: 0.7821\n",
            "Epoch 86/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7135 - accuracy: 0.7821\n",
            "Epoch 87/100\n",
            "3463/3463 [==============================] - 182s 53ms/step - loss: 0.7134 - accuracy: 0.7821\n",
            "Epoch 88/100\n",
            "3463/3463 [==============================] - 182s 53ms/step - loss: 0.7137 - accuracy: 0.7820\n",
            "Epoch 89/100\n",
            "3463/3463 [==============================] - 182s 53ms/step - loss: 0.7136 - accuracy: 0.7821\n",
            "Epoch 90/100\n",
            "3463/3463 [==============================] - 181s 52ms/step - loss: 0.7135 - accuracy: 0.7821\n",
            "Epoch 91/100\n",
            "3463/3463 [==============================] - 182s 53ms/step - loss: 0.7135 - accuracy: 0.7821\n",
            "Epoch 92/100\n",
            "3463/3463 [==============================] - 183s 53ms/step - loss: 0.7135 - accuracy: 0.7822\n",
            "Epoch 93/100\n",
            "3463/3463 [==============================] - 187s 54ms/step - loss: 0.7135 - accuracy: 0.7822\n",
            "Epoch 94/100\n",
            "3463/3463 [==============================] - 187s 54ms/step - loss: 0.7135 - accuracy: 0.7822\n",
            "Epoch 95/100\n",
            "3463/3463 [==============================] - 184s 53ms/step - loss: 0.7135 - accuracy: 0.7822\n",
            "Epoch 96/100\n",
            "3463/3463 [==============================] - 186s 54ms/step - loss: 0.7136 - accuracy: 0.7821\n",
            "Epoch 97/100\n",
            "3463/3463 [==============================] - 185s 53ms/step - loss: 0.7136 - accuracy: 0.7821\n",
            "Epoch 98/100\n",
            "3463/3463 [==============================] - 184s 53ms/step - loss: 0.7136 - accuracy: 0.7820\n",
            "Epoch 99/100\n",
            "3463/3463 [==============================] - 186s 54ms/step - loss: 0.7136 - accuracy: 0.7821\n",
            "Epoch 100/100\n",
            "3463/3463 [==============================] - 184s 53ms/step - loss: 0.7137 - accuracy: 0.7821\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f73bc35ef10>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed858ba4-b42b-4837-80d7-0434001a4b42"
      },
      "source": [
        ""
      ],
      "id": "ed858ba4-b42b-4837-80d7-0434001a4b42",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcIngq2iji3l"
      },
      "source": [
        "## 3.2 Инференс"
      ],
      "id": "rcIngq2iji3l"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6826c16c-648e-4145-a849-37ab87bbc618"
      },
      "source": [
        "def seq2seq_inference(input_seq):\n",
        "    state = encoder_model(input_seq)\n",
        "\n",
        "    target_seq = np.array([[target_char2idx['<START>']]])\n",
        "\n",
        "    decoded_sentence = ''\n",
        "    while True:\n",
        "        output_tokens, state = decoder_model(target_seq, state)\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = target_idx2char[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        if (sampled_char == '<END>' or\n",
        "           len(decoded_sentence) > max_dec_seq_length):\n",
        "            break\n",
        "\n",
        "        target_seq = np.array([[sampled_token_index]])\n",
        "\n",
        "    return decoded_sentence"
      ],
      "id": "6826c16c-648e-4145-a849-37ab87bbc618",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f11f944-d5cd-4a15-9777-8b53568f9297"
      },
      "source": [
        ""
      ],
      "id": "8f11f944-d5cd-4a15-9777-8b53568f9297",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMJfmYxejeh-"
      },
      "source": [
        "# 4. Результат"
      ],
      "id": "AMJfmYxejeh-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5397ae90-cfcf-4374-926e-42f842b44b1e",
        "outputId": "f3f313bf-306a-4e4f-9148-8accc18d0e70"
      },
      "source": [
        "for seq_index in range(0, 20):\n",
        "    input_seq = encoder_input_seqs[seq_index: seq_index + 1]\n",
        "    decoded_sentence = seq2seq_inference(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Result sentence:', decoded_sentence)\n",
        "    print('Target sentence:', target_texts[seq_index])"
      ],
      "id": "5397ae90-cfcf-4374-926e-42f842b44b1e",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Input sentence: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\n",
            "Result sentence: What do you mean?<END>\n",
            "Target sentence: Well, I thought we'd start with pronunciation, if that's okay with you.\n",
            "-\n",
            "Input sentence: Well, I thought we'd start with pronunciation, if that's okay with you.\n",
            "Result sentence: I don't know what you mean.<END>\n",
            "Target sentence: Not the hacking and gagging and spitting part.  Please.\n",
            "-\n",
            "Input sentence: Not the hacking and gagging and spitting part.  Please.\n",
            "Result sentence: What do you mean?<END>\n",
            "Target sentence: Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n",
            "-\n",
            "Input sentence: You're asking me out.  That's so cute. What's your name again?\n",
            "Result sentence: Just a little thing.<END>\n",
            "Target sentence: Forget it.\n",
            "-\n",
            "Input sentence: No, no, it's my fault -- we didn't have a proper introduction ---\n",
            "Result sentence: You don't have to take me to the bathroom.<END>\n",
            "Target sentence: Cameron.\n",
            "-\n",
            "Input sentence: Cameron.\n",
            "Result sentence: He was a good time.<END>\n",
            "Target sentence: The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\n",
            "-\n",
            "Input sentence: The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\n",
            "Result sentence: I don't know what you want.<END>\n",
            "Target sentence: Seems like she could get a date easy enough...\n",
            "-\n",
            "Input sentence: Why?\n",
            "Result sentence: I don't know.<END>\n",
            "Target sentence: Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\n",
            "-\n",
            "Input sentence: Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\n",
            "Result sentence: I don't know what you mean.<END>\n",
            "Target sentence: That's a shame.\n",
            "-\n",
            "Input sentence: Gosh, if only we could find Kat a boyfriend...\n",
            "Result sentence: What are you doing here?<END>\n",
            "Target sentence: Let me see what I can do.\n",
            "-\n",
            "Input sentence: C'esc ma tete. This is my head\n",
            "Result sentence: What do you mean?<END>\n",
            "Target sentence: Right.  See?  You're ready for the quiz.\n",
            "-\n",
            "Input sentence: Right.  See?  You're ready for the quiz.\n",
            "Result sentence: I don't know what you mean.<END>\n",
            "Target sentence: I don't want to know how to say that though.  I want to know useful things. Like where the good stores are.  How much does champagne cost?  Stuff like Chat.  I have never in my life had to point out my head to someone.\n",
            "-\n",
            "Input sentence: I don't want to know how to say that though.  I want to know useful things. Like where the good stores are.  How much does champagne cost?  Stuff like Chat.  I have never in my life had to point out my head to someone.\n",
            "Result sentence: What do you mean?<END>\n",
            "Target sentence: That's because it's such a nice one.\n",
            "-\n",
            "Input sentence: That's because it's such a nice one.\n",
            "Result sentence: What do you mean?<END>\n",
            "Target sentence: Forget French.\n",
            "-\n",
            "Input sentence: How is our little Find the Wench A Date plan progressing?\n",
            "Result sentence: No.<END>\n",
            "Target sentence: Well, there's someone I think might be --\n",
            "-\n",
            "Input sentence: There.\n",
            "Result sentence: What do you mean?<END>\n",
            "Target sentence: Where?\n",
            "-\n",
            "Input sentence: You got something on your mind?\n",
            "Result sentence: No.<END>\n",
            "Target sentence: I counted on you to help my cause. You and that thug are obviously failing. Aren't we ever going on our date?\n",
            "-\n",
            "Input sentence: You have my word.  As a gentleman\n",
            "Result sentence: I don't know.                                                    \n",
            "Target sentence: You're sweet.\n",
            "-\n",
            "Input sentence: How do you get your hair to look like that?\n",
            "Result sentence: I don't know.<END>\n",
            "Target sentence: Eber's Deep Conditioner every two days. And I never, ever use a blowdryer without the diffuser attachment.\n",
            "-\n",
            "Input sentence: Sure have.\n",
            "Result sentence: What do you mean?<END>\n",
            "Target sentence: I really, really, really wanna go, but I can't.  Not unless my sister goes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "954b5cb7-1fab-4b7b-8a1a-28c47fd90973"
      },
      "source": [
        ""
      ],
      "id": "954b5cb7-1fab-4b7b-8a1a-28c47fd90973",
      "execution_count": null,
      "outputs": []
    }
  ]
}